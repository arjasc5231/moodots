{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNonMel_st5fold.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjasc5231/moodots/blob/main/SER/CNN/CNNonMel_st5fold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIVT9oL0svxH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c12e47fc-dc61-44a8-9887-fb3a25f61403"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iI8jKgULPV_"
      },
      "source": [
        "#SERwithCNNonMel_moredropout.ipynb의 모델로 5fold해봄\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sklearn as sk\n",
        "import sklearn.model_selection"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOcuV6s4MEFw"
      },
      "source": [
        "learning_rate = 0.001\n",
        "training_epochs = 61\n",
        "batch_size = 100"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Srm3eVVJuJNB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35a3f115-6599-46f6-fff1-13afcfc6659f"
      },
      "source": [
        "mel_X_train, mel_X_test, mel_Y_train, mel_Y_test = np.load(\"/content/drive/MyDrive/team_runner/colab/dataset/emoDB/emo_mel_more.npy\", allow_pickle=True)\n",
        "mel_X = np.concatenate((mel_X_train, mel_X_test), axis=0)\n",
        "mel_Y = np.concatenate((mel_Y_train, mel_Y_test), axis=0)\n",
        "\n",
        "print(mel_X.shape)\n",
        "print(mel_Y.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(911, 128, 128)\n",
            "(911,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T50eCGEAyRXu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "385d855e-e7d0-4078-8f20-00f9cd4fcb0a"
      },
      "source": [
        "mel_X = np.expand_dims(mel_X, axis=-1)\n",
        "mel_Y_origin = mel_Y[:]\n",
        "mel_Y= to_categorical(mel_Y, 7)\n",
        "print(mel_X.shape)\n",
        "print(mel_Y_origin.shape)\n",
        "print(mel_Y.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(911, 128, 128, 1)\n",
            "(911,)\n",
            "(911, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6Uu2gRdyUep"
      },
      "source": [
        "def create_model():\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Conv2D(filters=32, kernel_size=3, activation=tf.nn.relu, padding='SAME', \n",
        "                                  input_shape=(128, 128, 1)))\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    model.add(keras.layers.Conv2D(filters=64, kernel_size=3, activation=tf.nn.relu, padding='SAME'))\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    model.add(keras.layers.Conv2D(filters=128, kernel_size=3, activation=tf.nn.relu, padding='SAME'))\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dense(256, activation=tf.nn.relu))\n",
        "    model.add(keras.layers.Dropout(0.5))\n",
        "    model.add(keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "    model.add(keras.layers.Dropout(0.5))\n",
        "    model.add(keras.layers.Dense(64, activation=tf.nn.relu))\n",
        "    model.add(keras.layers.Dropout(0.5))\n",
        "    model.add(keras.layers.Dense(7))\n",
        "    return model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIxR_4KLyXAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9efdc41-3310-4f16-c257-8c1f1c8b9efb"
      },
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 128, 128, 32)      320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 64, 64, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 256)               8388864   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 7)                 455       \n",
            "=================================================================\n",
            "Total params: 8,523,143\n",
            "Trainable params: 8,523,143\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-0PiEFdyY7T"
      },
      "source": [
        "def loss_fn(model, images, labels):\n",
        "    logits = model(images, training=True)\n",
        "    loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(\n",
        "        y_pred=logits, y_true=labels, from_logits=True))    \n",
        "    return loss"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5x6EkHUybJv"
      },
      "source": [
        "def grad(model, images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = loss_fn(model, images, labels)\n",
        "    return tape.gradient(loss, model.variables)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7AdZJecycsD"
      },
      "source": [
        "def evaluate(model, images, labels):\n",
        "    logits = model(images, training=False)\n",
        "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    return accuracy"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQEPnkEpyfHP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDbPf0WtygoC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae31b94d-1cf6-4410-8c5a-324c08762a15"
      },
      "source": [
        "print('Learning started. It takes sometime.')\n",
        "\n",
        "skfold = sk.model_selection.StratifiedKFold(n_splits=5, shuffle=True)\n",
        "fold = 1\n",
        "fold_acc = []\n",
        "for train_idx, test_idx in skfold.split(mel_X,mel_Y_origin): #kFold 생각나는대로 코딩한거라 비효율적일 수 있음. 인터넷에 검색해서 더 효율적인 코드로 수정하기\n",
        "  model = create_model()\n",
        "  optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
        "  \n",
        "  X_train, Y_train = mel_X[train_idx], mel_Y[train_idx]\n",
        "  X_test, Y_test = mel_X[test_idx], mel_Y[test_idx]\n",
        "\n",
        "  train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).batch(batch_size)\n",
        "  test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test)).batch(batch_size)\n",
        "\n",
        "  print(f'<<fold {fold}>>')\n",
        "\n",
        "  for epoch in range(training_epochs):\n",
        "    avg_loss = 0.\n",
        "    avg_train_acc = 0.\n",
        "    avg_test_acc = 0.\n",
        "    train_step = 0\n",
        "    test_step = 0\n",
        "\n",
        "    for images, labels in train_dataset:\n",
        "      grads = grad(model, images, labels)                \n",
        "      optimizer.apply_gradients(zip(grads, model.variables))\n",
        "      loss = loss_fn(model, images, labels)\n",
        "      acc = evaluate(model, images, labels)\n",
        "      avg_loss = avg_loss + loss\n",
        "      avg_train_acc = avg_train_acc + acc\n",
        "      train_step += 1\n",
        "    avg_loss = avg_loss / train_step\n",
        "    avg_train_acc = avg_train_acc / train_step\n",
        "    \n",
        "    conf_mat = [[0]*7 for i in range(7)]\n",
        "    for images, labels in test_dataset:        \n",
        "      acc = evaluate(model, images, labels)        \n",
        "      avg_test_acc = avg_test_acc + acc\n",
        "      test_step += 1\n",
        "    avg_test_acc = avg_test_acc / test_step   \n",
        "\n",
        "    if epoch%10==0: print('Epoch:', '{}'.format(epoch + 1), 'loss =', '{:.8f}'.format(avg_loss), \n",
        "          'train accuracy = ', '{:.4f}'.format(avg_train_acc), \n",
        "          'test accuracy = ', '{:.4f}'.format(avg_test_acc))\n",
        "  \n",
        "  fold_acc.append(avg_test_acc)\n",
        "  fold+=1\n",
        "\n",
        "  conf_mat = [[0]*7 for i in range(7)]\n",
        "  for images, labels in test_dataset:\n",
        "    logits = model(images, training=False)\n",
        "    logits_max = tf.math.argmax(logits,1)\n",
        "    labels_max = tf.math.argmax(labels,1)\n",
        "    for i in range(len(logits)): conf_mat[logits_max[i]][labels_max[i]]+=1\n",
        "  for i in range(7): print(conf_mat[i])\n",
        "  conf_mat_normal = []\n",
        "  for i in range(7):\n",
        "    s = sum(conf_mat[i])\n",
        "    if s==0: conf_mat_normal.append([0]*7)\n",
        "    else: conf_mat_normal.append(list(map(lambda x:(x/s)*100, conf_mat[i])))\n",
        "  label = ['anger','boredom','disgust','fear','happy','sad','neutral']\n",
        "  print('\\t'+'\\t'.join(label))\n",
        "  for i in range(7):\n",
        "    print(label[i], end='')\n",
        "    for j in range(7): print('\\t%2.0f'%conf_mat_normal[i][j], end=' ')\n",
        "    print()\n",
        "\n",
        "print('Learning Finished!')\n",
        "print('fold accuracy: ', fold_acc)\n",
        "print('average accuracy: ', sum(fold_acc)/(fold-1))\n",
        "#뒤로 갈수록 학습 성능이 떨어진다. 왜???"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning started. It takes sometime.\n",
            "<<fold 1>>\n",
            "Epoch: 1 loss = 2.01811934 train accuracy =  0.2007 test accuracy =  0.2164\n",
            "Epoch: 11 loss = 1.82735729 train accuracy =  0.3180 test accuracy =  0.3988\n",
            "Epoch: 21 loss = 1.28746176 train accuracy =  0.5096 test accuracy =  0.4760\n",
            "Epoch: 31 loss = 0.94543153 train accuracy =  0.7021 test accuracy =  0.5721\n",
            "Epoch: 41 loss = 0.59647751 train accuracy =  0.8848 test accuracy =  0.6262\n",
            "Epoch: 51 loss = 0.44707614 train accuracy =  0.9563 test accuracy =  0.6152\n",
            "Epoch: 61 loss = 0.30584332 train accuracy =  0.9937 test accuracy =  0.6071\n",
            "[31, 0, 1, 3, 8, 0, 0]\n",
            "[1, 18, 1, 2, 0, 8, 4]\n",
            "[1, 3, 11, 2, 1, 2, 1]\n",
            "[3, 0, 4, 6, 0, 0, 1]\n",
            "[4, 0, 0, 5, 9, 0, 2]\n",
            "[0, 2, 0, 0, 0, 23, 0]\n",
            "[0, 5, 2, 1, 4, 0, 14]\n",
            "\tanger\tboredom\tdisgust\tfear\thappy\tsad\tneutral\n",
            "anger\t72 \t 0 \t 2 \t 7 \t19 \t 0 \t 0 \n",
            "boredom\t 3 \t53 \t 3 \t 6 \t 0 \t24 \t12 \n",
            "disgust\t 5 \t14 \t52 \t10 \t 5 \t10 \t 5 \n",
            "fear\t21 \t 0 \t29 \t43 \t 0 \t 0 \t 7 \n",
            "happy\t20 \t 0 \t 0 \t25 \t45 \t 0 \t10 \n",
            "sad\t 0 \t 8 \t 0 \t 0 \t 0 \t92 \t 0 \n",
            "neutral\t 0 \t19 \t 8 \t 4 \t15 \t 0 \t54 \n",
            "<<fold 2>>\n",
            "Epoch: 1 loss = 1.97832918 train accuracy =  0.2232 test accuracy =  0.2248\n",
            "Epoch: 11 loss = 1.50173521 train accuracy =  0.4153 test accuracy =  0.4101\n",
            "Epoch: 21 loss = 1.13944614 train accuracy =  0.6741 test accuracy =  0.5494\n",
            "Epoch: 31 loss = 0.66663259 train accuracy =  0.9350 test accuracy =  0.6721\n",
            "Epoch: 41 loss = 0.35673654 train accuracy =  0.9900 test accuracy =  0.6710\n",
            "Epoch: 51 loss = 0.22156860 train accuracy =  0.9962 test accuracy =  0.6615\n",
            "Epoch: 61 loss = 0.19103058 train accuracy =  0.9937 test accuracy =  0.6715\n",
            "[28, 0, 2, 1, 0, 0, 0]\n",
            "[2, 22, 3, 1, 1, 7, 7]\n",
            "[1, 0, 10, 0, 0, 0, 0]\n",
            "[4, 2, 3, 12, 2, 0, 0]\n",
            "[5, 0, 0, 1, 12, 0, 1]\n",
            "[0, 2, 0, 2, 0, 26, 1]\n",
            "[1, 2, 1, 1, 6, 1, 12]\n",
            "\tanger\tboredom\tdisgust\tfear\thappy\tsad\tneutral\n",
            "anger\t90 \t 0 \t 6 \t 3 \t 0 \t 0 \t 0 \n",
            "boredom\t 5 \t51 \t 7 \t 2 \t 2 \t16 \t16 \n",
            "disgust\t 9 \t 0 \t91 \t 0 \t 0 \t 0 \t 0 \n",
            "fear\t17 \t 9 \t13 \t52 \t 9 \t 0 \t 0 \n",
            "happy\t26 \t 0 \t 0 \t 5 \t63 \t 0 \t 5 \n",
            "sad\t 0 \t 6 \t 0 \t 6 \t 0 \t84 \t 3 \n",
            "neutral\t 4 \t 8 \t 4 \t 4 \t25 \t 4 \t50 \n",
            "<<fold 3>>\n",
            "Epoch: 1 loss = 2.03373003 train accuracy =  0.2164 test accuracy =  0.2237\n",
            "Epoch: 11 loss = 1.69097197 train accuracy =  0.3941 test accuracy =  0.3901\n",
            "Epoch: 21 loss = 1.21110964 train accuracy =  0.6084 test accuracy =  0.4961\n",
            "Epoch: 31 loss = 0.71041584 train accuracy =  0.8669 test accuracy =  0.5722\n",
            "Epoch: 41 loss = 0.45268714 train accuracy =  0.9537 test accuracy =  0.5855\n",
            "Epoch: 51 loss = 0.24087365 train accuracy =  0.9987 test accuracy =  0.6299\n",
            "Epoch: 61 loss = 0.16659564 train accuracy =  0.9987 test accuracy =  0.6571\n",
            "[32, 0, 2, 4, 9, 0, 1]\n",
            "[0, 18, 2, 4, 1, 1, 8]\n",
            "[1, 3, 12, 3, 0, 0, 0]\n",
            "[3, 0, 2, 6, 1, 0, 1]\n",
            "[4, 0, 1, 0, 8, 0, 1]\n",
            "[0, 5, 0, 1, 1, 33, 0]\n",
            "[1, 1, 0, 0, 1, 0, 11]\n",
            "\tanger\tboredom\tdisgust\tfear\thappy\tsad\tneutral\n",
            "anger\t67 \t 0 \t 4 \t 8 \t19 \t 0 \t 2 \n",
            "boredom\t 0 \t53 \t 6 \t12 \t 3 \t 3 \t24 \n",
            "disgust\t 5 \t16 \t63 \t16 \t 0 \t 0 \t 0 \n",
            "fear\t23 \t 0 \t15 \t46 \t 8 \t 0 \t 8 \n",
            "happy\t29 \t 0 \t 7 \t 0 \t57 \t 0 \t 7 \n",
            "sad\t 0 \t12 \t 0 \t 2 \t 2 \t82 \t 0 \n",
            "neutral\t 7 \t 7 \t 0 \t 0 \t 7 \t 0 \t79 \n",
            "<<fold 4>>\n",
            "Epoch: 1 loss = 2.00305629 train accuracy =  0.2046 test accuracy =  0.2198\n",
            "Epoch: 11 loss = 1.71333015 train accuracy =  0.3924 test accuracy =  0.4067\n",
            "Epoch: 21 loss = 1.25102055 train accuracy =  0.5110 test accuracy =  0.5277\n",
            "Epoch: 31 loss = 0.94542617 train accuracy =  0.7790 test accuracy =  0.6293\n",
            "Epoch: 41 loss = 0.57860631 train accuracy =  0.9237 test accuracy =  0.6265\n",
            "Epoch: 51 loss = 0.36212623 train accuracy =  0.9825 test accuracy =  0.6171\n",
            "Epoch: 61 loss = 0.32196912 train accuracy =  0.9912 test accuracy =  0.6282\n",
            "[37, 0, 1, 2, 8, 0, 0]\n",
            "[0, 14, 1, 1, 0, 3, 13]\n",
            "[1, 5, 11, 2, 1, 1, 2]\n",
            "[0, 2, 3, 7, 0, 1, 0]\n",
            "[2, 0, 1, 7, 11, 0, 0]\n",
            "[0, 2, 1, 0, 0, 27, 0]\n",
            "[0, 4, 2, 0, 1, 1, 7]\n",
            "\tanger\tboredom\tdisgust\tfear\thappy\tsad\tneutral\n",
            "anger\t77 \t 0 \t 2 \t 4 \t17 \t 0 \t 0 \n",
            "boredom\t 0 \t44 \t 3 \t 3 \t 0 \t 9 \t41 \n",
            "disgust\t 4 \t22 \t48 \t 9 \t 4 \t 4 \t 9 \n",
            "fear\t 0 \t15 \t23 \t54 \t 0 \t 8 \t 0 \n",
            "happy\t10 \t 0 \t 5 \t33 \t52 \t 0 \t 0 \n",
            "sad\t 0 \t 7 \t 3 \t 0 \t 0 \t90 \t 0 \n",
            "neutral\t 0 \t27 \t13 \t 0 \t 7 \t 7 \t47 \n",
            "<<fold 5>>\n",
            "Epoch: 1 loss = 2.00772977 train accuracy =  0.2352 test accuracy =  0.2263\n",
            "Epoch: 11 loss = 1.53382277 train accuracy =  0.4072 test accuracy =  0.3940\n",
            "Epoch: 21 loss = 1.13837540 train accuracy =  0.6062 test accuracy =  0.4578\n",
            "Epoch: 31 loss = 0.76847762 train accuracy =  0.8121 test accuracy =  0.5327\n",
            "Epoch: 41 loss = 0.44666815 train accuracy =  0.9663 test accuracy =  0.6010\n",
            "Epoch: 51 loss = 0.26602897 train accuracy =  0.9950 test accuracy =  0.5971\n",
            "Epoch: 61 loss = 0.20751338 train accuracy =  1.0000 test accuracy =  0.5877\n",
            "[36, 1, 1, 2, 11, 0, 2]\n",
            "[0, 14, 3, 2, 0, 3, 5]\n",
            "[0, 3, 8, 7, 1, 0, 0]\n",
            "[0, 1, 2, 5, 3, 0, 1]\n",
            "[4, 0, 2, 2, 5, 0, 2]\n",
            "[0, 5, 0, 0, 0, 29, 2]\n",
            "[0, 3, 4, 1, 1, 1, 10]\n",
            "\tanger\tboredom\tdisgust\tfear\thappy\tsad\tneutral\n",
            "anger\t68 \t 2 \t 2 \t 4 \t21 \t 0 \t 4 \n",
            "boredom\t 0 \t52 \t11 \t 7 \t 0 \t11 \t19 \n",
            "disgust\t 0 \t16 \t42 \t37 \t 5 \t 0 \t 0 \n",
            "fear\t 0 \t 8 \t17 \t42 \t25 \t 0 \t 8 \n",
            "happy\t27 \t 0 \t13 \t13 \t33 \t 0 \t13 \n",
            "sad\t 0 \t14 \t 0 \t 0 \t 0 \t81 \t 6 \n",
            "neutral\t 0 \t15 \t20 \t 5 \t 5 \t 5 \t50 \n",
            "Learning Finished!\n",
            "fold accuracy:  [<tf.Tensor: shape=(), dtype=float32, numpy=0.6071085>, <tf.Tensor: shape=(), dtype=float32, numpy=0.67146343>, <tf.Tensor: shape=(), dtype=float32, numpy=0.65707314>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6281707>, <tf.Tensor: shape=(), dtype=float32, numpy=0.5876829>]\n",
            "average accuracy:  tf.Tensor(0.6302997, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "jHnz_IrJykNN",
        "outputId": "57ca1bb7-6cbd-4326-f9b7-594c8915db4a"
      },
      "source": [
        "conf_mat = [[0]*7 for i in range(7)] #mat[real_label]=predicted_label list\n",
        "print(conf_mat)\n",
        "for images, labels in test_dataset:\n",
        "  logits = model(images, training=False)\n",
        "  logits_max = tf.math.argmax(logits,1)\n",
        "  labels_max = tf.math.argmax(labels,1)\n",
        "  for i in range(len(logits)): conf_mat[logits_max[i]][labels_max[i]]+=1\n",
        "\n",
        "for i in range(7): print(conf_mat[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-47a3e3303bce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconf_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#mat[real_label]=predicted_label list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mlogits_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRQFL0_RYqVU"
      },
      "source": [
        "conf_mat_normal = []\n",
        "for i in range(7):\n",
        "  s = sum(conf_mat[i])\n",
        "  conf_mat_normal.append(list(map(lambda x:(x/s)*100, conf_mat[i])))\n",
        "\n",
        "label = ['anger','boredom','disgust','fear','happy','sad','neutral']\n",
        "print('\\t'+'\\t'.join(label))\n",
        "for i in range(7):\n",
        "  print(label[i], end='')\n",
        "  for j in range(7): print('\\t%2.0f'%conf_mat_normal[i][j], end=' ')\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}