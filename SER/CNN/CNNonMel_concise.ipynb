{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNonMel_concise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1yfpEAmp_zjS3zkgiovtYQAbLxqTIuZER",
      "authorship_tag": "ABX9TyPHkYJ3sNvw1+VDUwFbS9RG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjasc5231/moodots/blob/main/SER/CNN/CNNonMel_concise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iI8jKgULPV_"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOcuV6s4MEFw"
      },
      "source": [
        "learning_rate = 0.001 #0.01은 학습이 전혀 안됨\n",
        "training_epochs = 60\n",
        "batch_size = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Srm3eVVJuJNB",
        "outputId": "a078411b-5211-4d9a-8821-1f34af99fa1a"
      },
      "source": [
        "mel_X_train, mel_X_test, mel_Y_train, mel_Y_test = np.load(\"/content/drive/MyDrive/team_runner/colab/dataset/emoDB/emo_mel_more.npy\", allow_pickle=True)\n",
        "\n",
        "print(mel_X_train.shape)\n",
        "print(mel_Y_train.shape)\n",
        "print(mel_X_test.shape)\n",
        "print(mel_Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(683, 128, 128)\n",
            "(683,)\n",
            "(228, 128, 128)\n",
            "(228,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T50eCGEAyRXu"
      },
      "source": [
        "mel_X_train = np.expand_dims(mel_X_train, axis=-1)\n",
        "mel_X_test = np.expand_dims(mel_X_test, axis=-1)\n",
        "\n",
        "mel_Y_train = to_categorical(mel_Y_train, 7)\n",
        "mel_Y_test = to_categorical(mel_Y_test, 7)    \n",
        "\n",
        "mel_train_dataset = tf.data.Dataset.from_tensor_slices((mel_X_train, mel_Y_train)).batch(batch_size)\n",
        "mel_test_dataset = tf.data.Dataset.from_tensor_slices((mel_X_test, mel_Y_test)).batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6Uu2gRdyUep"
      },
      "source": [
        "def create_model():\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Conv2D(filters=32, kernel_size=3, activation=tf.nn.relu, padding='SAME',input_shape=(128, 128, 1)))\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME')\n",
        "    model.add(keras.layers.Conv2D(filters=64, kernel_size=3, activation=tf.nn.relu, padding='SAME'))\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    model.add(keras.layers.Conv2D(filters=128, kernel_size=3, activation=tf.nn.relu, padding='SAME'))\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dense(256, activation=tf.nn.relu))\n",
        "    model.add(keras.layers.Dropout(0.5))\n",
        "    model.add(keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "    model.add(keras.layers.Dropout(0.5))\n",
        "    model.add(keras.layers.Dense(64, activation=tf.nn.relu))\n",
        "    model.add(keras.layers.Dropout(0.5))\n",
        "    model.add(keras.layers.Dense(7))\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIxR_4KLyXAe",
        "outputId": "f0b83696-e178-4709-8be6-7588d1cd1dc2"
      },
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 128, 128, 32)      320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 64, 64, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               8388864   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 7)                 455       \n",
            "=================================================================\n",
            "Total params: 8,523,143\n",
            "Trainable params: 8,523,143\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-0PiEFdyY7T"
      },
      "source": [
        "def loss_fn(model, images, labels):\n",
        "    logits = model(images, training=True)\n",
        "    loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_pred=logits, y_true=labels, from_logits=True))    \n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5x6EkHUybJv"
      },
      "source": [
        "def grad(model, images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = loss_fn(model, images, labels)\n",
        "    return tape.gradient(loss, model.variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7AdZJecycsD"
      },
      "source": [
        "def evaluate(model, images, labels):\n",
        "    logits = model(images, training=False)\n",
        "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQEPnkEpyfHP"
      },
      "source": [
        "optimizer = tf.optimizers.Adam(learning_rate=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDbPf0WtygoC",
        "outputId": "6b6fd47b-232b-4f38-8ae8-3858f8be2ce0"
      },
      "source": [
        "print('Learning started. It takes sometime.')\n",
        "print('Epoch\\tloss\\t\\ttrain acc\\ttest acc')\n",
        "for epoch in range(training_epochs):\n",
        "    loss = 0.\n",
        "    train_acc = 0.\n",
        "    test_acc = 0.\n",
        "    \n",
        "    for images, labels in mel_train_dataset:\n",
        "        grads = grad(model, images, labels)                \n",
        "        optimizer.apply_gradients(zip(grads, model.variables)) \n",
        "        loss += loss_fn(model, images, labels)\n",
        "        train_acc += evaluate(model, images, labels)\n",
        "    loss = loss / len(mel_train_dataset)\n",
        "    train_acc = train_acc / len(mel_train_dataset)\n",
        "    \n",
        "    for images, labels in mel_test_dataset:\n",
        "        test_acc += evaluate(model, images, labels)\n",
        "    test_acc = test_acc / len(mel_test_dataset)  \n",
        "\n",
        "    print('{}  \\t{:.4f}  \\t{:.4f}  \\t{:.4f}'.format(epoch+1, loss, train_acc, test_acc))\n",
        "\n",
        "print('Learning Finished!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning started. It takes sometime.\n",
            "Epoch\tloss\t\ttrain acc\ttest acc\n",
            "1  \t1.9223  \t0.2261  \t0.2200\n",
            "2  \t1.9186  \t0.2261  \t0.2200\n",
            "3  \t1.9232  \t0.2261  \t0.2200\n",
            "4  \t1.9095  \t0.2261  \t0.2200\n",
            "5  \t1.8973  \t0.2324  \t0.2519\n",
            "6  \t1.8807  \t0.2739  \t0.2519\n",
            "7  \t1.8310  \t0.3828  \t0.3610\n",
            "8  \t1.7632  \t0.3888  \t0.4114\n",
            "9  \t1.6860  \t0.3974  \t0.4114\n",
            "10  \t1.6090  \t0.3902  \t0.4114\n",
            "11  \t1.5554  \t0.3931  \t0.4114\n",
            "12  \t1.5085  \t0.4002  \t0.4048\n",
            "13  \t1.4033  \t0.4051  \t0.4300\n",
            "14  \t1.4273  \t0.4234  \t0.4114\n",
            "15  \t1.4283  \t0.4125  \t0.4500\n",
            "16  \t1.4075  \t0.4528  \t0.4248\n",
            "17  \t1.3274  \t0.4649  \t0.4938\n",
            "18  \t1.2809  \t0.4940  \t0.5176\n",
            "19  \t1.2620  \t0.5549  \t0.4786\n",
            "20  \t1.1901  \t0.5627  \t0.5171\n",
            "21  \t1.1348  \t0.6467  \t0.5524\n",
            "22  \t1.1067  \t0.6850  \t0.5490\n",
            "23  \t1.0233  \t0.7441  \t0.5638\n",
            "24  \t0.9880  \t0.7505  \t0.5519\n",
            "25  \t0.9744  \t0.7682  \t0.5838\n",
            "26  \t0.9025  \t0.7871  \t0.5857\n",
            "27  \t0.8821  \t0.7993  \t0.5671\n",
            "28  \t0.8351  \t0.8185  \t0.5938\n",
            "29  \t0.8479  \t0.8271  \t0.5724\n",
            "30  \t0.7587  \t0.8840  \t0.6095\n",
            "31  \t0.7511  \t0.8685  \t0.6262\n",
            "32  \t0.6559  \t0.8728  \t0.6310\n",
            "33  \t0.6204  \t0.9120  \t0.6343\n",
            "34  \t0.6064  \t0.9211  \t0.6157\n",
            "35  \t0.6458  \t0.9063  \t0.6157\n",
            "36  \t0.5398  \t0.9311  \t0.6510\n",
            "37  \t0.5620  \t0.9448  \t0.6614\n",
            "38  \t0.5416  \t0.9454  \t0.6224\n",
            "39  \t0.5034  \t0.9686  \t0.6290\n",
            "40  \t0.4250  \t0.9506  \t0.6310\n",
            "41  \t0.4921  \t0.9783  \t0.6476\n",
            "42  \t0.4422  \t0.9757  \t0.6329\n",
            "43  \t0.3678  \t0.9800  \t0.6695\n",
            "44  \t0.3561  \t0.9883  \t0.6190\n",
            "45  \t0.4307  \t0.9900  \t0.6862\n",
            "46  \t0.3827  \t0.9883  \t0.6495\n",
            "47  \t0.4133  \t0.9940  \t0.6833\n",
            "48  \t0.3190  \t0.9929  \t0.6410\n",
            "49  \t0.3162  \t0.9900  \t0.6310\n",
            "50  \t0.3004  \t0.9943  \t0.6662\n",
            "51  \t0.3189  \t0.9971  \t0.6610\n",
            "52  \t0.2983  \t1.0000  \t0.6629\n",
            "53  \t0.2960  \t0.9986  \t0.6595\n",
            "54  \t0.3167  \t0.9929  \t0.6138\n",
            "55  \t0.2961  \t1.0000  \t0.6171\n",
            "56  \t0.2763  \t0.9986  \t0.6071\n",
            "57  \t0.2559  \t1.0000  \t0.6562\n",
            "58  \t0.2331  \t0.9971  \t0.6710\n",
            "59  \t0.1884  \t0.9986  \t0.6610\n",
            "60  \t0.2144  \t0.9986  \t0.6676\n",
            "Learning Finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHnz_IrJykNN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b64fb936-642f-4c39-cd17-ccd65083264c"
      },
      "source": [
        "conf_mat = [[0]*7 for i in range(7)] #mat[real_label]=predicted_label list\n",
        "\n",
        "for images, labels in mel_test_dataset:\n",
        "  logits = model(images, training=False)\n",
        "  logits_max = tf.math.argmax(logits,1)\n",
        "  labels_max = tf.math.argmax(labels,1)\n",
        "  for i in range(len(logits)): conf_mat[labels_max[i]][logits_max[i]]+=1\n",
        "\n",
        "for i in range(7): print(conf_mat[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46, 0, 0, 0, 2, 0, 0]\n",
            "[0, 24, 2, 0, 1, 5, 4]\n",
            "[5, 0, 18, 1, 0, 1, 4]\n",
            "[7, 2, 0, 7, 3, 2, 5]\n",
            "[7, 0, 7, 1, 6, 0, 3]\n",
            "[0, 4, 1, 1, 0, 37, 0]\n",
            "[1, 4, 1, 0, 0, 0, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRQFL0_RYqVU",
        "outputId": "c0c7951d-a1c9-4574-d41f-dae5505f59b8"
      },
      "source": [
        "conf_mat_normal = []\n",
        "for i in range(7):\n",
        "  s = sum(conf_mat[i])\n",
        "  conf_mat_normal.append(list(map(lambda x:(x/s)*100, conf_mat[i])))\n",
        "\n",
        "label = ['anger','boredom','disgust','fear','happy','sad','neutral']\n",
        "print('\\t'+'\\t'.join(label))\n",
        "for i in range(7):\n",
        "  print(label[i], end='')\n",
        "  for j in range(7): print('\\t%2.0f'%conf_mat_normal[i][j], end=' ')\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tanger\tboredom\tdisgust\tfear\thappy\tsad\tneutral\n",
            "anger\t96 \t 0 \t 0 \t 0 \t 4 \t 0 \t 0 \n",
            "boredom\t 0 \t67 \t 6 \t 0 \t 3 \t14 \t11 \n",
            "disgust\t17 \t 0 \t62 \t 3 \t 0 \t 3 \t14 \n",
            "fear\t27 \t 8 \t 0 \t27 \t12 \t 8 \t19 \n",
            "happy\t29 \t 0 \t29 \t 4 \t25 \t 0 \t12 \n",
            "sad\t 0 \t 9 \t 2 \t 2 \t 0 \t86 \t 0 \n",
            "neutral\t 5 \t18 \t 5 \t 0 \t 0 \t 0 \t73 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN8pw0J-6TBl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}