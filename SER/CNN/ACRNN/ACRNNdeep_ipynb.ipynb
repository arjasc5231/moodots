{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ACRNNdeep.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjasc5231/moodots/blob/ACRNN/SER/CNN/ACRNNdeep_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMUivsks6xrt",
        "outputId": "18efc038-625e-44e1-cb4c-91e32e4021ff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iI8jKgULPV_"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/team_runner/colab/emoDB/CNN\")\n",
        "from kfold import kfold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOcuV6s4MEFw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52cd9a23-767e-45a6-9d87-66d6247113dc"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = np.load(\"/content/drive/MyDrive/team_runner/colab/dataset/emoDB/emo_mel_3d.npy\", allow_pickle=True)  # 0.8070+-0.0354\n",
        "#X_train, X_test, Y_train, Y_test = np.load(\"/content/drive/MyDrive/team_runner/colab/dataset/emoDB/emo_mel_more.npy\", allow_pickle=True) # 정확도 0.8049+-0.0349 (0.74가 한 번 나와서 많이 낮아짐)\n",
        "X = np.concatenate((X_train, X_test), axis=0)\n",
        "#X = np.expand_dims(X, axis=-1)\n",
        "Y = np.concatenate((Y_train, Y_test), axis=0)\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(911, 128, 128, 3)\n",
            "(911,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6Uu2gRdyUep"
      },
      "source": [
        "\"\"\"\n",
        "attention 이론은 https://wikidocs.net/22893 참고\n",
        "Bahdanau방식 https://github.com/philipperemy/keras-attention-mechanism 참고\n",
        "ACRNN 논문에서는 LSTM의 마지막 출력값도 사용하지 않은 특이한 attention을 사용...\n",
        "  논문 코드 https://github.com/xuanjihe/speech-emotion-recognition/blob/master/crnn.py 에서 u_omega의 역할을 이해 못했음 일단 빼고 구현\n",
        "https://stackoverflow.com/questions/42918446/how-to-add-an-attention-mechanism-in-keras?answertab=votes#tab-top repeatvector를 이용하기도 하네\n",
        "https://github.com/keras-team/keras/issues/1472 여기도 참고\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def create_model():\n",
        "    inputs = keras.Input(shape=(128, 128, 3))\n",
        "    #inputs = keras.Input(shape=(128, 128, 1))\n",
        "    conv1 = keras.layers.Conv2D(filters=32, kernel_size=[3, 3], padding='same', activation=tf.nn.relu)(inputs)\n",
        "    pool1 = keras.layers.MaxPool2D()(conv1)\n",
        "    conv2 = keras.layers.Conv2D(filters=64, kernel_size=[3, 3], padding='same', activation=tf.nn.relu)(pool1)\n",
        "    pool2 = keras.layers.MaxPool2D()(conv2)\n",
        "    conv3 = keras.layers.Conv2D(filters=128, kernel_size=[3, 3], padding='same', activation=tf.nn.relu)(pool2)\n",
        "    pool3 = keras.layers.MaxPool2D()(conv3)\n",
        "    # conv2까지만 있어도 큰 차이는 없는듯?\n",
        "\n",
        "    trans = keras.layers.Permute((2,1,3))(pool3)\n",
        "    reshape = keras.layers.Reshape((-1, 16*128))(trans) # 열 개수(freq축)*ch\n",
        "    linear = keras.layers.Dense(512)(reshape)\n",
        "    lstm = keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True, dropout=0.5))(linear) # (time=15,hidden=256)\n",
        "\n",
        "    attention_score1 = keras.layers.Dense(1, activation='tanh')(lstm) # lstm(time,hidden)*W(hidden,1)=score(time,1)\n",
        "    attention_score2 = keras.layers.Softmax()(attention_score1)\n",
        "    attention = keras.layers.Dot(axes=(1,1))([lstm, attention_score2]) # (time=15, hidden=256) * (time,) => (hidden=256)\n",
        "    flatten = keras.layers.Flatten()(attention)\n",
        "    \n",
        "    #drop1 = keras.layers.Dropout(0.5)(flatten) #drop1,2 추가시 0.7586 +- 0.0238\n",
        "    fc = keras.layers.Dense(128)(flatten)\n",
        "    drop2 = keras.layers.Dropout(0.5)(fc)\n",
        "    output = keras.layers.Dense(7)(drop2)\n",
        "    return keras.Model(inputs=inputs, outputs=output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIxR_4KLyXAe",
        "outputId": "aaafbfa3-269d-4e11-b120-17fce5ae5c15"
      },
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 128, 128, 32) 896         input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling2D) (None, 64, 64, 32)   0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 64, 64, 64)   18496       max_pooling2d_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling2D) (None, 32, 32, 64)   0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 32, 32, 128)  73856       max_pooling2d_19[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling2D) (None, 16, 16, 128)  0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "permute_6 (Permute)             (None, 16, 16, 128)  0           max_pooling2d_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "reshape_6 (Reshape)             (None, 16, 2048)     0           permute_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_24 (Dense)                (None, 16, 512)      1049088     reshape_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_6 (Bidirectional) (None, 16, 256)      656384      dense_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_25 (Dense)                (None, 16, 1)        257         bidirectional_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "softmax_6 (Softmax)             (None, 16, 1)        0           dense_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dot_6 (Dot)                     (None, 256, 1)       0           bidirectional_6[0][0]            \n",
            "                                                                 softmax_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 256)          0           dot_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_26 (Dense)                (None, 128)          32896       flatten_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 128)          0           dense_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_27 (Dense)                (None, 7)            903         dropout_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,832,776\n",
            "Trainable params: 1,832,776\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDbPf0WtygoC",
        "outputId": "da9ef6cb-1f62-4ea1-df5c-a6a103aae4e7"
      },
      "source": [
        "kfold(5, create_model, X, Y, 0.001, 100, 120, 10) # 예상보다 정확도가 안나온다. attention을 잘못 사용하고있거나(논문의 model.py함수 그대로 따라해보자.), attention의 장점을 살리기 위해 인풋의 크기를 키우거나."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning started. k=5\n",
            "<<fold 1>>\n",
            "Epoch\tloss\t\ttrain acc\ttest acc\n",
            "10  \t1.0543  \t0.6232  \t0.5933\n",
            "20  \t0.6268  \t0.8229  \t0.6704\n",
            "30  \t0.3257  \t0.9205  \t0.6934\n",
            "40  \t0.1446  \t0.9700  \t0.7295\n",
            "50  \t0.1148  \t0.9800  \t0.6763\n",
            "60  \t0.1879  \t0.9375  \t0.7445\n",
            "70  \t0.0390  \t0.9962  \t0.7917\n",
            "80  \t0.0043  \t1.0000  \t0.7936\n",
            "90  \t0.0016  \t1.0000  \t0.7996\n",
            "100  \t0.0028  \t1.0000  \t0.7857\n",
            "110  \t0.0007  \t1.0000  \t0.7716\n",
            "120  \t0.0100  \t1.0000  \t0.7054\n",
            "max train accuracy: 1.0000\n",
            "max test accuracy: 0.8017\n",
            "<<fold 2>>\n",
            "Epoch\tloss\t\ttrain acc\ttest acc\n",
            "10  \t0.9347  \t0.7147  \t0.6127\n",
            "20  \t0.4353  \t0.8844  \t0.6893\n",
            "30  \t0.2183  \t0.9550  \t0.7098\n",
            "40  \t0.1495  \t0.9762  \t0.6954\n",
            "50  \t0.1001  \t0.9788  \t0.7176\n",
            "60  \t0.0230  \t1.0000  \t0.7309\n",
            "70  \t0.0011  \t1.0000  \t0.7359\n",
            "80  \t0.0011  \t1.0000  \t0.7087\n",
            "90  \t0.0049  \t1.0000  \t0.7115\n",
            "100  \t0.0008  \t1.0000  \t0.7165\n",
            "110  \t0.0013  \t1.0000  \t0.7237\n",
            "120  \t0.0002  \t1.0000  \t0.7298\n",
            "max train accuracy: 1.0000\n",
            "max test accuracy: 0.7480\n",
            "<<fold 3>>\n",
            "Epoch\tloss\t\ttrain acc\ttest acc\n",
            "10  \t0.9802  \t0.6755  \t0.6321\n",
            "20  \t0.5506  \t0.8439  \t0.7591\n",
            "30  \t0.2739  \t0.9388  \t0.7280\n",
            "40  \t0.3511  \t0.8907  \t0.7348\n",
            "50  \t0.0632  \t0.9963  \t0.8096\n",
            "60  \t0.0475  \t0.9925  \t0.7852\n",
            "70  \t0.0032  \t1.0000  \t0.8285\n",
            "80  \t0.0012  \t1.0000  \t0.8285\n",
            "90  \t0.0009  \t1.0000  \t0.8346\n",
            "100  \t0.0042  \t1.0000  \t0.8407\n",
            "110  \t0.0069  \t1.0000  \t0.7752\n",
            "120  \t0.0710  \t0.9887  \t0.8418\n",
            "max train accuracy: 1.0000\n",
            "max test accuracy: 0.8579\n",
            "<<fold 4>>\n",
            "Epoch\tloss\t\ttrain acc\ttest acc\n",
            "10  \t1.0252  \t0.6711  \t0.6543\n",
            "20  \t0.5896  \t0.8253  \t0.7613\n",
            "30  \t0.3111  \t0.9325  \t0.7491\n",
            "40  \t0.2817  \t0.9269  \t0.7570\n",
            "50  \t0.1366  \t0.9800  \t0.7702\n",
            "60  \t0.0361  \t0.9975  \t0.7741\n",
            "70  \t0.0280  \t0.9975  \t0.7724\n",
            "80  \t0.0132  \t1.0000  \t0.8013\n",
            "90  \t0.1385  \t0.9750  \t0.7502\n",
            "100  \t0.0088  \t1.0000  \t0.7670\n",
            "110  \t0.0049  \t1.0000  \t0.7559\n",
            "120  \t0.0021  \t1.0000  \t0.7720\n",
            "max train accuracy: 1.0000\n",
            "max test accuracy: 0.8196\n",
            "<<fold 5>>\n",
            "Epoch\tloss\t\ttrain acc\ttest acc\n",
            "10  \t1.0886  \t0.6462  \t0.6460\n",
            "20  \t0.7283  \t0.7733  \t0.7026\n",
            "30  \t0.3458  \t0.9013  \t0.7137\n",
            "40  \t0.2640  \t0.9282  \t0.7420\n",
            "50  \t0.1978  \t0.9462  \t0.7591\n",
            "60  \t0.0577  \t0.9975  \t0.7563\n",
            "70  \t0.0067  \t1.0000  \t0.7674\n",
            "80  \t0.0028  \t1.0000  \t0.7907\n",
            "90  \t0.0017  \t1.0000  \t0.7735\n",
            "100  \t0.0450  \t0.9987  \t0.7552\n",
            "110  \t0.0066  \t1.0000  \t0.7924\n",
            "120  \t0.0147  \t0.9987  \t0.8074\n",
            "max train accuracy: 1.0000\n",
            "max test accuracy: 0.8079\n",
            "\n",
            "Learning Finished!\n",
            "average train accuracy: 1.0000\n",
            "average test accuracy: 0.8070\n",
            "test std: 0.0354\n",
            "\n",
            "\tanger\tboredom\tdisgust\tfear\thappy\tsad\tneutral\t#\n",
            "anger\t94 \t 0 \t 1 \t 0 \t 4 \t 0 \t 0 \t202 \n",
            "boredom\t 0 \t76 \t 3 \t 2 \t 1 \t 9 \t 9 \t137 \n",
            "disgust\t 3 \t 6 \t71 \t 6 \t 5 \t 3 \t 5 \t97 \n",
            "fear\t 8 \t 4 \t 3 \t63 \t14 \t 3 \t 4 \t93 \n",
            "happy\t27 \t 0 \t 4 \t 8 \t60 \t 1 \t 0 \t106 \n",
            "sad\t 0 \t 9 \t 1 \t 0 \t 0 \t87 \t 2 \t167 \n",
            "neutral\t 1 \t23 \t 1 \t 4 \t 3 \t 3 \t66 \t109 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN8pw0J-6TBl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
