{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simpleRNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjasc5231/moodots/blob/main/SER/RNN/simpleRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osVYavpeTdLf",
        "outputId": "ecd87d4b-98ee-4a2e-92bd-3c55c5b5daa1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iI8jKgULPV_"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sklearn as sk\n",
        "import librosa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOcuV6s4MEFw"
      },
      "source": [
        "learning_rate = 0.001\n",
        "training_epochs = 61\n",
        "batch_size = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Srm3eVVJuJNB",
        "outputId": "73b6cb67-e410-44ea-f11b-d97efa8906d6"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = np.load(\"/content/drive/MyDrive/team_runner/colab/dataset/emoDB/forRNN_downsamp.npy\", allow_pickle=True)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1585, 5000)\n",
            "(1585,)\n",
            "(529, 5000)\n",
            "(529,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T50eCGEAyRXu"
      },
      "source": [
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "Y_train = to_categorical(Y_train, 7)\n",
        "Y_test = to_categorical(Y_test, 7)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).shuffle(buffer_size=100000).batch(batch_size)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test)).batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJvAPfhw7AKS",
        "outputId": "6f2c0446-a354-4cf5-f171-a09212c5ecfb"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1585, 5000, 1)\n",
            "(1585, 7)\n",
            "(529, 5000, 1)\n",
            "(529, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6Uu2gRdyUep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d7adda6-6947-4bbc-d448-46f13508d8ba"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.SimpleRNN(100, input_shape=(5000, 1), activation=tf.nn.relu))\n",
        "model.add(keras.layers.Dense(7))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_1 (SimpleRNN)     (None, 100)               10200     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7)                 707       \n",
            "=================================================================\n",
            "Total params: 10,907\n",
            "Trainable params: 10,907\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-0PiEFdyY7T"
      },
      "source": [
        "def loss_fn(model, images, labels):\n",
        "    logits = model(images, training=True)\n",
        "    loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(\n",
        "        y_pred=logits, y_true=labels, from_logits=True))    \n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5x6EkHUybJv"
      },
      "source": [
        "def grad(model, images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = loss_fn(model, images, labels)\n",
        "    return tape.gradient(loss, model.variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7AdZJecycsD"
      },
      "source": [
        "def evaluate(model, images, labels):\n",
        "    logits = model(images, training=False)\n",
        "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQEPnkEpyfHP"
      },
      "source": [
        "optimizer = tf.optimizers.Adam(learning_rate=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDbPf0WtygoC",
        "outputId": "da75f772-013a-4d47-ff8d-ca6bbfb0d76e"
      },
      "source": [
        "print('Learning started. It takes sometime.')\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "  avg_loss = 0.\n",
        "  avg_train_acc = 0.\n",
        "  avg_test_acc = 0.\n",
        "  train_step = 0\n",
        "  test_step = 0\n",
        "\n",
        "  for waves, labels in train_dataset:\n",
        "    grads = grad(model, waves, labels)                \n",
        "    optimizer.apply_gradients(zip(grads, model.variables))\n",
        "    loss = loss_fn(model, waves, labels)\n",
        "    acc = evaluate(model, waves, labels)\n",
        "    avg_loss = avg_loss + loss\n",
        "    avg_train_acc = avg_train_acc + acc\n",
        "    train_step += 1\n",
        "  avg_loss = avg_loss / train_step\n",
        "  avg_train_acc = avg_train_acc / train_step\n",
        "  \n",
        "  for waves, labels in test_dataset:        \n",
        "    acc = evaluate(model, waves, labels)        \n",
        "    avg_test_acc = avg_test_acc + acc\n",
        "    test_step += 1\n",
        "  avg_test_acc = avg_test_acc / test_step   \n",
        "\n",
        "  print('Epoch:', '{}'.format(epoch + 1), 'loss =', '{:.8f}'.format(avg_loss), \n",
        "        'train accuracy = ', '{:.4f}'.format(avg_train_acc), \n",
        "        'test accuracy = ', '{:.4f}'.format(avg_test_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning started. It takes sometime.\n",
            "Epoch: 1 loss = 1.93055236 train accuracy =  0.2056 test accuracy =  0.2245\n",
            "Epoch: 2 loss = 1.91025805 train accuracy =  0.2241 test accuracy =  0.2261\n",
            "Epoch: 3 loss = 1.91911495 train accuracy =  0.2332 test accuracy =  0.2328\n",
            "Epoch: 4 loss = 1.91337740 train accuracy =  0.2125 test accuracy =  0.2419\n",
            "Epoch: 5 loss = 1.90747023 train accuracy =  0.2465 test accuracy =  0.2261\n",
            "Epoch: 6 loss = 1.90178657 train accuracy =  0.2256 test accuracy =  0.2302\n",
            "Epoch: 7 loss = 1.88682854 train accuracy =  0.2479 test accuracy =  0.2886\n",
            "Epoch: 8 loss = 1.91168141 train accuracy =  0.2149 test accuracy =  0.2302\n",
            "Epoch: 9 loss = 1.89790797 train accuracy =  0.2646 test accuracy =  0.2876\n",
            "Epoch: 10 loss = 1.89139915 train accuracy =  0.2861 test accuracy =  0.2967\n",
            "Epoch: 11 loss = 1.87186384 train accuracy =  0.2832 test accuracy =  0.2951\n",
            "Epoch: 12 loss = 1.85485935 train accuracy =  0.2801 test accuracy =  0.2826\n",
            "Epoch: 13 loss = 1.84477937 train accuracy =  0.2622 test accuracy =  0.2552\n",
            "Epoch: 14 loss = 1.89895904 train accuracy =  0.1932 test accuracy =  0.1630\n",
            "Epoch: 15 loss = 1.90091300 train accuracy =  0.2354 test accuracy =  0.2261\n",
            "Epoch: 16 loss = 1.86858201 train accuracy =  0.2482 test accuracy =  0.2402\n",
            "Epoch: 17 loss = 1.87529254 train accuracy =  0.2168 test accuracy =  0.2676\n",
            "Epoch: 18 loss = 1.89376783 train accuracy =  0.2043 test accuracy =  0.2204\n",
            "Epoch: 19 loss = 1.89149070 train accuracy =  0.2638 test accuracy =  0.2901\n",
            "Epoch: 20 loss = 1.89574122 train accuracy =  0.2442 test accuracy =  0.2776\n",
            "Epoch: 21 loss = 1.90144527 train accuracy =  0.2327 test accuracy =  0.2261\n",
            "Epoch: 22 loss = 1.88349867 train accuracy =  0.2245 test accuracy =  0.2261\n",
            "Epoch: 23 loss = 1.86698556 train accuracy =  0.2274 test accuracy =  0.2328\n",
            "Epoch: 24 loss = 1.85991204 train accuracy =  0.2435 test accuracy =  0.2602\n",
            "Epoch: 25 loss = 1.85409880 train accuracy =  0.2633 test accuracy =  0.2826\n",
            "Epoch: 26 loss = 1.84945655 train accuracy =  0.2700 test accuracy =  0.2826\n",
            "Epoch: 27 loss = 1.84460235 train accuracy =  0.2733 test accuracy =  0.2867\n",
            "Epoch: 28 loss = 1.84164858 train accuracy =  0.2707 test accuracy =  0.2851\n",
            "Epoch: 29 loss = 1.83493698 train accuracy =  0.2741 test accuracy =  0.2951\n",
            "Epoch: 30 loss = 1.82888985 train accuracy =  0.2810 test accuracy =  0.2893\n",
            "Epoch: 31 loss = 1.82251120 train accuracy =  0.2775 test accuracy =  0.2917\n",
            "Epoch: 32 loss = 1.82698369 train accuracy =  0.2698 test accuracy =  0.2934\n",
            "Epoch: 33 loss = 1.81764591 train accuracy =  0.2868 test accuracy =  0.3001\n",
            "Epoch: 34 loss = 1.81484723 train accuracy =  0.2873 test accuracy =  0.2967\n",
            "Epoch: 35 loss = 1.81140864 train accuracy =  0.2846 test accuracy =  0.2984\n",
            "Epoch: 36 loss = 1.81349242 train accuracy =  0.2933 test accuracy =  0.3158\n",
            "Epoch: 37 loss = 1.80894458 train accuracy =  0.2906 test accuracy =  0.3158\n",
            "Epoch: 38 loss = 1.80562043 train accuracy =  0.2913 test accuracy =  0.2926\n",
            "Epoch: 39 loss = 1.80569959 train accuracy =  0.2972 test accuracy =  0.2969\n",
            "Epoch: 40 loss = 1.80626178 train accuracy =  0.2950 test accuracy =  0.2993\n",
            "Epoch: 41 loss = 1.80489802 train accuracy =  0.2916 test accuracy =  0.2993\n",
            "Epoch: 42 loss = 1.80398476 train accuracy =  0.2936 test accuracy =  0.2936\n",
            "Epoch: 43 loss = 1.80121171 train accuracy =  0.2961 test accuracy =  0.2993\n",
            "Epoch: 44 loss = 1.80314696 train accuracy =  0.2872 test accuracy =  0.2910\n",
            "Epoch: 45 loss = 1.80443549 train accuracy =  0.2865 test accuracy =  0.2976\n",
            "Epoch: 46 loss = 1.79983377 train accuracy =  0.2909 test accuracy =  0.2926\n",
            "Epoch: 47 loss = 1.80053735 train accuracy =  0.2876 test accuracy =  0.2910\n",
            "Epoch: 48 loss = 1.79930854 train accuracy =  0.2866 test accuracy =  0.2960\n",
            "Epoch: 49 loss = 1.79672694 train accuracy =  0.2932 test accuracy =  0.2976\n",
            "Epoch: 50 loss = 1.79867625 train accuracy =  0.2871 test accuracy =  0.2893\n",
            "Epoch: 51 loss = 1.80240178 train accuracy =  0.2842 test accuracy =  0.2876\n",
            "Epoch: 52 loss = 1.79505432 train accuracy =  0.2846 test accuracy =  0.2967\n",
            "Epoch: 53 loss = 1.79549718 train accuracy =  0.2783 test accuracy =  0.2910\n",
            "Epoch: 54 loss = 1.79203200 train accuracy =  0.2885 test accuracy =  0.2943\n",
            "Epoch: 55 loss = 1.78820205 train accuracy =  0.2825 test accuracy =  0.2943\n",
            "Epoch: 56 loss = 1.78662956 train accuracy =  0.2861 test accuracy =  0.2943\n",
            "Epoch: 57 loss = 1.78901327 train accuracy =  0.2826 test accuracy =  0.2926\n",
            "Epoch: 58 loss = 1.78281116 train accuracy =  0.2851 test accuracy =  0.2984\n",
            "Epoch: 59 loss = 1.78422797 train accuracy =  0.2849 test accuracy =  0.2984\n",
            "Epoch: 60 loss = 1.78178012 train accuracy =  0.2842 test accuracy =  0.2984\n",
            "Epoch: 61 loss = 1.78349888 train accuracy =  0.2834 test accuracy =  0.2967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHnz_IrJykNN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "349636a3-be38-4050-f146-1db6be7c58c3"
      },
      "source": [
        "conf_mat = [[0]*7 for i in range(7)] #mat[real_label]=predicted_label list\n",
        "\n",
        "for images, labels in test_dataset:\n",
        "  logits = model(images, training=False)\n",
        "  logits_max = tf.math.argmax(logits,1)\n",
        "  labels_max = tf.math.argmax(labels,1)\n",
        "  for i in range(len(logits)): conf_mat[labels_max[i]][logits_max[i]]+=1\n",
        "\n",
        "for i in range(7): print(conf_mat[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[33, 0, 3, 3, 9, 0, 0]\n",
            "[0, 19, 4, 0, 0, 12, 13]\n",
            "[0, 1, 4, 0, 0, 0, 0]\n",
            "[3, 3, 6, 8, 1, 2, 2]\n",
            "[5, 0, 1, 5, 10, 0, 2]\n",
            "[0, 2, 0, 1, 1, 19, 0]\n",
            "[0, 2, 1, 2, 0, 0, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRQFL0_RYqVU",
        "outputId": "23b8df66-fbb9-43f6-a020-9ebc87fb3b65"
      },
      "source": [
        "conf_mat_normal = []\n",
        "for i in range(7):\n",
        "  s = sum(conf_mat[i])\n",
        "  conf_mat_normal.append(list(map(lambda x:(x/s)*100, conf_mat[i])))\n",
        "\n",
        "label = ['anger','boredom','disgust','fear','happy','sad','neutral']\n",
        "print('\\t'+'\\t'.join(label))\n",
        "for i in range(7):\n",
        "  print(label[i], end='')\n",
        "  for j in range(7): print('\\t%2.0f'%conf_mat_normal[i][j], end=' ')\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tanger\tboredom\tdisgust\tfear\thappy\tsad\tneutral\n",
            "anger\t69 \t 0 \t 6 \t 6 \t19 \t 0 \t 0 \n",
            "boredom\t 0 \t40 \t 8 \t 0 \t 0 \t25 \t27 \n",
            "disgust\t 0 \t20 \t80 \t 0 \t 0 \t 0 \t 0 \n",
            "fear\t12 \t12 \t24 \t32 \t 4 \t 8 \t 8 \n",
            "happy\t22 \t 0 \t 4 \t22 \t43 \t 0 \t 9 \n",
            "sad\t 0 \t 9 \t 0 \t 4 \t 4 \t83 \t 0 \n",
            "neutral\t 0 \t20 \t10 \t20 \t 0 \t 0 \t50 \n"
          ]
        }
      ]
    }
  ]
}